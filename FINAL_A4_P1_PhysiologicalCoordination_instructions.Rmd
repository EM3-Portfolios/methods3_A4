---
title: "Assignment 4 - Heart rate, respiration and interpersonal coordination"
author: "Riccardo Fusaroli"
date: "August 20, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 4 - Heart rate, respiration and interpersonal coordination

Physiological data (here heart rate [variability], and respiration) are increasingly popular. Historically treated as pernicious noise to be regressed out of neuro-imaging data, there is now increasing research on how these signals tell us something important about cognition and beyond being just a signal of cognitive processes also impact them in interesting ways. Advanced sport science, and the quantified self movement (closely followed by marketing and communication) have hailed continuous physiological tracking as a powerful way to access and modify attitudes, habits, and performance. Further, as team coordination (in the military, in decision processes and organizational contexts) is more and more in focus, research has attempted to measure how interpersonal coordination between physiological systems might tell us something important about e.g. emotional and cognitive coordination. See references in the reading list for more on this.

In this assignment, you will learn to:
- pre-process physiological data (and grow further your mad R skills)
- model the continuous interdependence between two signals (using a multilevel model as proxy for a dynamical system approach)
- conservatively assess the presence of coordination between to signals in a controlled context

This assignment has two parts. The first part familiarizes you with heart rate, and respiration data and their preprocessing. The second part explores how to analyze interpersonal coordination of these signals.

These are the questions you need to be able to answer at the end of the assignment (aka that you need to submit as part of the portfolio)

1) How do you preprocess heart rate and respiration data? Describe the process. If any data needs to be excluded, list the excluded data and motivate the exclusion.
  *ECG excluded, the .txt and .xlsx files, *

2) Do you observe interpersonal coordination in heart rate and respiration? Describe your control baseline, the method used to quantify coordination, and the statistical models used to infer whether coordination was higher than in the baseline. Report the results of the models.

3) Do you observe differences in coordination between conditions? Report the models and results.

4) Is respiration coordination a likely driver of heart rate coordination? Describe how you would test for it. Bonus points if you actually run the tests and report methods and results.

N.B. N.B. The data are collected by students from previous years (Study 1 - 4). Note that synchronous and turn-taking are the same across all four studies, but the third condition is different: in the first year it was self-paced joint reading; in the second to fourth years it was the tv-series conversation.

## Let's get started

### Exploring physiological signals
The data files can be found here: https://www.dropbox.com/sh/bvvk7t3fvsplh9o/AADM6q4WrtXKvSwH5aAO1umta?dl=0

  - Choose one pair (one pair, three conditions, three files)
- Load the logs
- Produce a plot of the participants' respiration signal and a different one of the participants' HR signal.
  N.B: remember the slides: artifacts, downsampling, scaling.
  N.B. The gridExtra::grid.arrange() function allows you to display the plots side by side. E.g. grid.arrange(plot1, plot2, plot3, ncol=3). There are also smarter packages, like cowplot and ggpubr.
- Can you eye-ball which condition if any displays more physiological coordination?

### First we read one data file and identify the procedure
- Load the file
- correctly identify all columns
- plot the data
- deal with the artifacts
- downsample the data
- Add a column for study, group, trial and condition

```{r First we read one data file and identify the procedure, Anne}
# Load the libraries
pacman::p_load(tidyverse, groupdata2)

# Load the file
file <- read_csv("./data/Study4_G8_T1_TurnTaking.csv")

# Plot raw data
ggplot(data = file) +
  geom_path(aes(TimeMs, HR1, color = "P1")) + 
  geom_path(aes(TimeMs, HR2, color = "P2")) + 
  labs(x = "time", y = "HR") + 
  theme_classic() +
  ggtitle("Raw data")

# Remove outliers
removeOuts <- function(ts, threshold){
  higher_threshold_condition <- ts > (mean(ts, na.rm = T) + (threshold*sd(ts, na.rm = T)))
  lower_threshold_condition <- ts < (mean(ts, na.rm = T) - (threshold*sd(ts, na.rm = T)))
  ts[higher_threshold_condition] <- NA
  ts[lower_threshold_condition] <- NA
  return(ts)
}
threshold=3
file <- file %>% # applying the function to the data (all the variables)
  mutate(HR1 = removeOuts(HR1, threshold),
         HR2 = removeOuts(HR2, threshold),
         Resp1 = removeOuts(Resp1, threshold),
         Resp2 = removeOuts(Resp2, threshold))

# Plot data with the artifacts/outliers removed
ggplot(data = file) +
  geom_path(aes(TimeMs, HR1, color = "P1")) + 
  geom_path(aes(TimeMs, HR2, color = "P2")) + 
  labs(x = "time", y = "HR") + 
  theme_classic() +
  ggtitle("Artifacts removed")

# Scale
file$HR1 <- scale(file$HR1)
file$HR2 <- scale(file$HR2)
file$Resp1 <- scale(file$Resp1)
file$Resp2 <- scale(file$Resp2)

# Plot scaled data
ggplot(data = file) +
  geom_path(aes(TimeMs, HR1, color = "P1")) + 
  geom_path(aes(TimeMs, HR2, color = "P2")) + 
  labs(x = "time", y = "HR") + 
  theme_classic() +
  ggtitle("Scaled data")

# Downsample
file_ds <- file %>% group(n = 100, method = "greedy") %>% # n=100 means that we want our data to be 100 times smaller
  dplyr::summarise(TimeMs = mean(TimeMs, na.rm = T),
                   HR1 = mean(HR1, na.rm = T),
                   HR2 = mean(HR2, na.rm = T),
                   Resp1 = mean(Resp1, na.rm = T),
                   Resp2 = mean(Resp2, na.rm = T))
# NOTE! we want to be consistent in how much we downsample to avoid over-representing data in small sets.
# This is why we will downsample all files by the same amount when we get to the pre-processing function.

## Plot the downsampled data
ggplot(data = file_ds) +
  geom_path(aes(TimeMs, HR1, color = "P1")) + 
  geom_path(aes(TimeMs, HR2, color = "P2")) + 
  labs(x = "time", y = "HR") + 
  theme_classic() +
  ggtitle("Downsampled data")
```


## Now we are ready to go to load and pre-process all files

Go through all the files (with a function passed onto map_df), check which files should be excluded, if any, and save the pre-processed time-series. This procedure is similar to what you have done in portfolio 3. You may use the code you wrote for that assignment and adjust it to this one.

A couple of tips:
- looping will be too slow for these files (remember you have ~200 000 rows in each file!). Making a function and using Map/Map_df is your salvation.
- you may want your first step after loading a file to be downsampling, so that you don't work with enormous amount of data
- each study restarts the group numbering, so you should make sure to change that (e.g. 100 * Study + Group)
- you need to make sure all the data are meaningful or something has to be removed. Plotting is your friend. E.g. "Study1_G1_T1_Synchronous" has one bad respiration signal. We could replace it with NAs


```{r data preprocessing function, Manon & Lærke}
# Define a function running the loading, artifact removal, scaling, downsampling, info adding.

d1 <- as.data.frame(NULL)

data_preprocess <- function(filename, threshold = 3){
  #loading data
  d <- read_csv(paste0("data/", filename))
  
  # renaming the TimeMs column to time to conform study 4 to the others
  names(d)[names(d) == "TimeMs"] <- "time"
  
  # Downsample
  d <- d %>% group(n = 100, method = "greedy") %>% 
    dplyr::summarise(time = mean(time, na.rm = T),
                   HR1 = mean(HR1, na.rm = T),
                   HR2 = mean(HR2, na.rm = T),
                   Resp1 = mean(Resp1, na.rm = T),
                   Resp2 = mean(Resp2, na.rm = T))
  
  # creating columns from filenames
  d$Trial <- ""
  d$Trial <- str_extract(filename, "T.")
  d$Study <- ""
  d$Study <- str_extract(filename, "Study.")
  d$Group <- ""
  d$Group <- str_extract(filename, "G..")
  d$Group <- str_replace_all(d$Group, "[[:punct:]]", "") #this will avoid the ID 310 problem described in q1 of report
  d$Task <- ""
  d$Task <- str_extract(filename, "........csv")
  
  # Removing and adding things:
  d$Trial <- str_replace_all(d$Trial, c("T" = ""))
  d$Group <- str_replace_all(d$Group, c("G" = ""))
  d$Study <- str_replace_all(d$Study, c("Study" = ""))
  d$Task <- str_replace_all(d$Task, c(".csv" = ""))
  d$Task <- str_replace_all(d$Task, c("lfPaced" = "SelfPaced", "nTaking" = "TurnTaking", "hronous" = "Synchronous", "rsation" = "Conversation", "tGuided" = "MovementGuided", "entCoop" = "MovementCoop"))
  
  # Making a unique ID column
  d$ID <- paste(d$Study, d$Group, sep = "", collapse = NULL)
  
  # Removing outliers
  d <- d %>%
    mutate(HR1 = removeOuts(HR1, threshold),
         HR2 = removeOuts(HR2, threshold),
         Resp1 = removeOuts(Resp1, threshold),
         Resp2 = removeOuts(Resp2, threshold))
  d <- na.omit(d, cols = c("HR1", "HR2", "Resp1", "Resp2"), invert = FALSE) # remove the NAs we made from outliers
  
  # Scale
  d$HR1 <- scale(d$HR1)
  d$HR2 <- scale(d$HR2)
  d$Resp1 <- scale(d$Resp1)
  d$Resp2 <- scale(d$Resp2)
  
  return(d)
}



#  Identify all files to be read
filenames_list <- list.files(path = "data/", pattern = "*.csv")

# Run the function on the whole dataset using map_df
d1 <- map_df(filenames_list, data_preprocess)
```



```{r plotting inspecting and saving data, Cecilie}
# Now we need to make sure all the data are meaningful or something has to be removed
# E.g. "Study1_G1_T1_Synchronous" has one bad respiration signal. We could replace it with NAs

# This function plots the HR values of a given group in all conditions
plot_taskpergroup <- function(id, d1){
  p <- d1 %>% 
    group_by(ID) %>%
    mutate(time = seq(n())) %>% #"this is where we are going to solve that issue"
    subset(ID == id) %>%
    ggplot() + 
    geom_line(aes(time, HR1, color ="HR1")) + 
    geom_line(aes(time, HR2, color = "HR2")) + #plotting 2 lines
    labs(y = "HR") +
    ggtitle(paste("HR for each person of group ", id, " in each condition")) +
    theme_classic() + 
    facet_wrap(Task ~., ncol = 1)
  p
  return(p)
}

plot_taskpergroup(11, d1)



# This function plots the Resp values of a given group in all conditions
plot_taskpergroup_Resp <- function(id, d1){
  p <- d1 %>% 
    group_by(ID) %>%
    mutate(time = seq(n())) %>% #"this is where we are going to solve that issue"
    subset(ID == id) %>%
    ggplot() + 
    geom_line(aes(time, Resp1, color ="Resp1")) + 
    geom_line(aes(time, Resp2, color = "Resp2")) + #plotting 2 lines
    labs(y = "Respiration") +
    ggtitle(paste("Respiration for each person of group ", id, " in each condition")) +
    theme_classic() + 
    facet_wrap(Task ~., ncol = 1)
  p
  return(p)
}

plot_taskpergroup_Resp(11, d1)  # Resp 1 in group 11 is still bad (in synchronous and turntaking)
                                # Resp 2 in group 12 is bad (in synchronous)

# Remove bad data
d1$Resp1[d1$ID == 11 & d1$Task == "Synchronous"] <- NA
d1$Resp2[d1$ID == 11 & d1$Task == "Synchronous"] <- NA # remove the partner also (but not the whole row, because we want to leave HR alone)
d1$Resp1[d1$ID == 11 & d1$Task == "TurnTaking"] <- NA
d1$Resp2[d1$ID == 11 & d1$Task == "TurnTaking"] <- NA

d1$Resp1[d1$ID == 12 & d1$Task == "Synchronous"] <- NA
d1$Resp2[d1$ID == 12 & d1$Task == "Synchronous"] <- NA
plot_taskpergroup_Resp(12, d1)

# Save the data

```



## Now we need to run some analysis

Let's start with a multilevel model that accounts for 
- stability (how each signal is autocorrelated)
- interpersonal dependence (each signal is dependent from the previous state of the other signal)

The data needs to be further prepared, so we can analyze both participants in the same model.
We need to turn the data into a long format:
- a column indicating own hr and one own respiration
- a column indicating other hr and one other respiration
- a column indicating change in hr from previous round and one in respiration

We can then run an analysis where change is a function of one's previous state (stability, see slides), and the other's previous state (coupling). Make sure to:
- set up the most interesting contrasts: how do these parameters vary by condition? which condition should be baseline?
- set up the right random effects.
- N.B. the model will be slow. Make sure it works on a subset of the data first!

Bonus question: what if we include an additional layer? Is my heart rate just adjusting to yours, or also to how much you are adjusting to mine?
- to start answering this we can add a column indicating the previous change in hr in the other and one in respiration
- we can then build on the previous models by also adding the previous change in the other


```{r Make the data long, Lærke}
# Make the data long, so we can analyze both participants at the same time.
# Set the most interesting contrast e.g. by defining synchronous or conversation as the baseline (M:what?)

subset1 <- d1 %>%
  dplyr::summarise(Trial = Trial,
                   Study = Study,
                   Group = Group,
                   Task = Task,
                   ID = ID,
                   time = time,
                   HR_self = HR1,
                   HR_other = HR2,
                   Resp_self = Resp1,
                   Resp_other = Resp2)

subset2 <- d1 %>%
  dplyr::summarise(Trial = Trial,
                   Study = Study,
                   Group = Group,
                   Task = Task,
                   ID = ID,
                   time = time,
                   HR_self = HR2,
                   HR_other = HR1,
                   Resp_self = Resp2,
                   Resp_other = Resp1)

subset1$Participant <- 1
subset2$Participant <- 2

# Making unique ID per participant:
subset1$ParticipantID <- paste(subset1$ID, subset1$Participant, sep = "", collapse = NULL)
subset2$ParticipantID <- paste(subset2$ID, subset2$Participant, sep = "", collapse = NULL)

# Merging the two
dlong <- rbind(subset1, subset2)



# Generate a column for each: previous HR1, HR2, Resp1, Resp2. Tip: use the function Lag()
pacman::p_load(Hmisc, tidyverse)

dlong <- dlong %>%
  group_by(ParticipantID, Task) %>%
  mutate(HR_self_lead = Hmisc::Lag(HR_self, -1),
         HR_other_lead = Hmisc::Lag(HR_other, -1),
         Resp_self_lead = Hmisc::Lag(Resp_self, -1),
         Resp_other_lead = Hmisc::Lag(Resp_other, -1))


# Generate a column for each: change in HR1, HR2, Resp1, Resp2
dlong$HR_self_change <- dlong$HR_self_lead - dlong$HR_self
dlong$HR_other_change <- dlong$HR_other_lead - dlong$HR_other

dlong$Resp_self_change <- dlong$Resp_self_lead - dlong$Resp_self
dlong$Resp_other_change <- dlong$Resp_other_lead - dlong$Resp_other
## N.B. This is a bit tricky and you might have to do it in several steps

```


```{r Modeling 1 HR, Alba}
# Model change as a function of own and other previous state 
pacman::p_load(lme4, lmerTest)

# Making a column for the difference in HR between self and other
dlong <- dlong %>%
  mutate(diff_HR = HR_other - HR_self)

# The model:
HR_m <- lmerTest::lmer(HR_self_change ~ (HR_self + diff_HR) : Task + (1 + Task | ParticipantID), dlong, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

summary(HR_m)
```


```{r Modeling 1 Resp, Alba}
# Model change as a function of own and other previous state 
pacman::p_load(lme4, lmerTest)

# Making a column for the difference in HR between self and other
dlong <- dlong %>%
  mutate(diff_Resp = Resp_other - Resp_self)

# The model:
Resp_m <- lmerTest::lmer(Resp_self_change ~ (Resp_self + diff_Resp) : Task + (1 + Task | ParticipantID), subset(dlong, Study == "3"), REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

summary(Resp_m)
```



## Now we need to create control baselines.

First shuffled controls, then surrogate pairs.

### Creating controls: shuffled controls

Shuffled controls break the temporal dependencies of time-series by shuffling the value within one time-series. This ensures the "coordination" observed is not due to the actual values in the series and not their sequence.
Tip: sample() is your friend, but make sure to shuffle things within participant/condition and not throughout the whole dataset
 
```{r Create shuffled controls, Manon}
# Create a shuffled dataset
pacman::p_load(tidyverse)

control <- dlong %>% 
  group_by(ParticipantID, Task) %>%
  mutate(HR_self = HR_self[sample(row_number())],
         HR_other = HR_other[sample(row_number())],
         Resp_self = Resp_self[sample(row_number())],
         Resp_other = Resp_other[sample(row_number())]
         )

control$Control <- 1

# Making lag and change values based on the new self and other values:
control <- control %>%
  group_by(ParticipantID, Task) %>%
  mutate(HR_self_lead = Hmisc::Lag(HR_self, -1),
         HR_other_lead = Hmisc::Lag(HR_other, -1),
         Resp_self_lead = Hmisc::Lag(Resp_self, -1),
         Resp_other_lead = Hmisc::Lag(Resp_other, -1))

# Generate a column for each: change in HR1, HR2, Resp1, Resp2
control$HR_self_change <- control$HR_self_lead - control$HR_self
control$HR_other_change <- control$HR_other_lead - control$HR_other

control$Resp_self_change <- control$Resp_self_lead - control$Resp_self
control$Resp_other_change <- control$Resp_other_lead - control$Resp_other

control$diff <- NULL
control$ParticipantID <- paste0(control$ParticipantID, "_c")


# Concatenate it to the original dataset (and remember to have a column telling you which is which)
dlonger <- dlong

dlonger$diff <- NULL

dlonger$Control <- 0

dlonger <- rbind(dlonger, control)
dlonger$ID <- NULL
```
 

```{r shuffle - Modeling 2 HR - across tasks, Anne}
# Create the same models as in the previous chunk, but adding an interaction by shuffled vs. real
pacman::p_load(lme4, lmerTest, tidyverse)

dlonger <- dlonger %>%
  mutate(diff_HR = HR_other - HR_self)

dlonger$Control <- as.factor(dlonger$Control)

# The model:
m1_HR_shuff <- lmerTest::lmer(HR_self_change ~ 0+ (HR_self + diff_HR) : Control + (1 | ParticipantID), dlonger, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))
summary(m1_HR_shuff)
```


```{r shuffle - Modeling 2 HR - within task, Cecilie}
# Create the same models as in the previous chunk, but adding an interaction by shuffled vs. real
pacman::p_load(lme4, lmerTest, tidyverse)

dlonger <- dlonger %>%
  mutate(diff_HR = HR_other - HR_self)

dlonger$Control <- as.factor(dlonger$Control)

# The model:
m5.2_HR_shuff <- lmerTest::lmer(HR_self_change ~ 0+ (HR_self + diff_HR) : Task : Control + (1 | ParticipantID), dlonger, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))
summary(m5.2_HR_shuff)
```
 
 
 
### TRICKY! Creating controls: surrogate pair controls
 - Per each real pair, identify at least one surrogate pair (matching one of the participants, with somebody doing the same task, but in a different pair)

```{r Making surrogate pairs, Cecilie, Lærke, Manon}
# Making a copy dataset to work with (just in case we change something in it)
d2 <- d1

pacman::p_load(Hmisc, tidyverse)

# Creating the change and lead columns in this data
d2 <- d2 %>%
  group_by(ID, Task) %>%
  mutate(HR1_lead = Hmisc::Lag(HR1, -1),
         HR2_lead = Hmisc::Lag(HR2, -1),
         Resp1_lead = Hmisc::Lag(Resp1, -1),
         Resp2_lead = Hmisc::Lag(Resp2, -1))


# Generate a column for each: change in HR1, HR2, Resp1, Resp2
d2$HR1_change <- d2$HR1_lead - d2$HR1
d2$HR2_change <- d2$HR2_lead - d2$HR2

d2$Resp1_change <- d2$Resp1_lead - d2$Resp1
d2$Resp2_change <- d2$Resp2_lead - d2$Resp2



# Create vector with group IDs / Lists with group Id per individual study:
d2$ID <- as.numeric(as.character(d2$ID))
d2$Task <- as.factor(d2$Task)

# Making new pairs:
Groups <- unique(d2$ID[d2$Study == 1])
SurrogateList1 <- expand.grid(a = Groups, b = Groups)
SurrogateList1 <- subset(SurrogateList1, a != b)

Groups <- unique(d2$ID[d2$Study == 2])
SurrogateList2 <- expand.grid(a = Groups, b = Groups)
SurrogateList2 <- subset(SurrogateList2, a != b)

Groups <- unique(d2$ID[d2$Study == 3])
SurrogateList3 <- expand.grid(a = Groups, b = Groups)
SurrogateList3 <- subset(SurrogateList2, a != b)

SurrogateList <- rbind(SurrogateList1, SurrogateList2, SurrogateList3)


# Creating a loop for the resp of the work
for (i in 1:nrow(SurrogateList)) {
  x <- subset(d2, ID == SurrogateList$a[i])
  y <- subset(d2, ID == SurrogateList$b[i])
  group <- 800 + i # Creating new IDs for surrogate list
  for (task in c("Synchronous", "TurnTaking", "SelfPaced", "Conversation", "MovementGuided", "MovementCoop")) {
    #Making sure that we pair up by conditions
    if (task %in% unique(x$Task) & task %in% unique(y$Task)) {
      z3 <- subset(x, Task == task)
      z4 <- subset(y, Task == task)
  }
    if (nrow(z3) > nrow(z4)) {
      z3 <- z3[-((nrow(z4)+1):nrow(z3)),]
    }
        if (nrow(z4) > nrow(z3)) {
      z4 <- z4[-((nrow(z3)+1):nrow(z4)),]
        }
    w1 <- z3 %>% mutate(
      HR2 = z4$HR2,
      Resp2 = z4$Resp2,
      HR2_lead = z4$HR2_lead,
      Resp2_lead = z4$Resp2_lead,
      HR2_change = z4$HR2_change,
      Resp2_change = z4$Resp2_change
    )
    w1$ID <- group
    w1$Type <- "Surrogate"
    w <- w1
    if(exists("d_surrogate")) {d_surrogate <- rbind(d_surrogate, w)} else{(d_surrogate <- w)}
  }
}



# Making the surrogate data long:
subset3 <- d_surrogate %>%
  dplyr::summarise(Trial = Trial,
                   Study = Study,
                   Group = Group,
                   Task = Task,
                   ID = ID,
                   time = time,
                   Type = Type,
                   HR_self = HR1,
                   HR_other = HR2,
                   Resp_self = Resp1,
                   Resp_other = Resp2,
                   HR_self_change = HR1_change,
                   HR_other_change = HR2_change,
                   Resp_self_change = Resp1_change,
                   Resp_other_change = Resp2_change)

subset4 <- d_surrogate %>%
  dplyr::summarise(Trial = Trial,
                   Study = Study,
                   Group = Group,
                   Task = Task,
                   ID = ID,
                   time = time,
                   Type = Type,
                   HR_self = HR2,
                   HR_other = HR1,
                   Resp_self = Resp2,
                   Resp_other = Resp1,
                   HR_self_change = HR2_change,
                   HR_other_change = HR1_change,
                   Resp_self_change = Resp2_change,
                   Resp_other_change = Resp1_change)

subset3$Participant <- 1
subset4$Participant <- 2

# Making unique ID per participant:
subset3$ParticipantID <- paste(subset3$ID, subset3$Participant, sep = "", collapse = NULL)
subset4$ParticipantID <- paste(subset4$ID, subset4$Participant, sep = "", collapse = NULL)

# Merging the two
d_surrogate_long <- rbind(subset3, subset4)


# Concatenate it to the original dataset (and remember to have a column telling you which is which)
dlong_surrogate <- dlong

dlong_surrogate$diff <- NULL
d_surrogate_long$diff <- NULL

dlong_surrogate$Type <- "Original"

dlong_surrogate$ID <- NULL
d_surrogate_long$ID <- NULL

dlong_surrogate <- rbind(dlong_surrogate, d_surrogate_long)
```


```{r surrogate - Modeling 3 HR - across tasks, Alba}
dlong_surrogate <- dlong_surrogate %>%
  mutate(diff_HR = HR_other - HR_self)

dlong_surrogate$Type <- as.factor(dlong_surrogate$Type)

m3_HR_surrogate <- lmerTest::lmer(HR_self_change ~ 0+ (HR_self + diff_HR) : Type + (1 | ParticipantID), dlong_surrogate, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

summary(m3_HR_surrogate)
```

 
```{r surrogate - Modeling 3 HR - within task, Anne}
m7_HR_surrogate <- lmerTest::lmer(HR_self_change ~ 0+ (HR_self + diff_HR) : Task : Type + (1 | ParticipantID), dlong_surrogate, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

summary(m7_HR_surrogate)
```


```{r surrogate - Modeling 3 Resp - across tasks, Manon}
# Create the same models as in the previous chunk, but adding an interaction by shuffled vs. real

dlong_surrogate <- dlong_surrogate %>%
  mutate(diff_Resp = Resp_other - Resp_self)

dlong_surrogate$Type <- as.factor(dlong_surrogate$Type)

m4_Resp_surrogate <- lmerTest::lmer(Resp_self_change ~ 0+ (Resp_self + diff_Resp) : Type + (1 | ParticipantID), dlong_surrogate, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

summary(m4_Resp_surrogate)
```

 
```{r surrogate - Modeling 3 Resp - within task, Manon}
m8_Resp_surrogate <- lmerTest::lmer(Resp_self_change ~ 0+ (Resp_self + diff_Resp) : Task : Type + (1 | ParticipantID), dlong_surrogate, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

summary(m8_Resp_surrogate)
```
 
 
 


### Effects of respiration coordination on heart rate coordination
 - describe how you would test those.
 - Optional: run the models and report them

 
```{r, Anne}
# 4) Is respiration coordination a likely driver of heart rate coordination? Describe how you would test for it. Bonus points if you actually run the tests and report methods and results.

m9_HR_by_Resp <- lmerTest::lmer(diff_HR ~ 0+ (Resp_self + diff_Resp) : Task + (1 | ParticipantID), dlong, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

m9_HR_by_Resp <- lmerTest::lmer(diff_HR ~ 0+ diff_Resp : Task : Control + (1 | ParticipantID), dlonger, REML = F, control = lmerControl(optimizer = "nloptwrap", calc.derivs = F))

summary(m9_HR_by_Resp)
```
 
 
 